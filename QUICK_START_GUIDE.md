# ç«‹å³å¼€å§‹ï¼šç¬¬ä¸€å‘¨å¼€å‘æŒ‡å— ğŸš€

> **å½“å‰é˜¶æ®µ**: Week 1-2 æ ¸å¿ƒæ¨¡å‹åŸºç¡€
> 
> **æœ¬å‘¨ç›®æ ‡**: é›†æˆæ”¹è¿›çš„è§†è§‰ç¼–ç å™¨ï¼Œå®Œå–„è®­ç»ƒå¾ªç¯ï¼ŒéªŒè¯åŸºç¡€åŠŸèƒ½

---

## ğŸ“‹ æœ¬å‘¨ä»»åŠ¡æ¸…å•ï¼ˆWeek 1ï¼‰

### Day 1-2: é›†æˆæ”¹è¿›çš„è§†è§‰ç¼–ç å™¨

#### âœ… ä»»åŠ¡1: ä¿®æ”¹ä¸»æ¨¡å‹æ¶æ„

```bash
# 1. æ‰“å¼€ä¸»æ¨¡å‹æ–‡ä»¶
code D:\OpenMind\src\model_architecture.py
```

**éœ€è¦ä¿®æ”¹çš„å†…å®¹**:

```python
# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥
from improved_vision_encoder import (
    ImprovedVisionEncoder,
    ImprovedProjector
)

# æ‰¾åˆ° MultimodalReasoningModel ç±»çš„ __init__ æ–¹æ³•
# æ›¿æ¢åŸæ¥çš„ VisionEncoder

class MultimodalReasoningModel(nn.Module):
    def __init__(self, config):
        super().__init__()
        
        # === ä¿®æ”¹è¿™éƒ¨åˆ† ===
        # æ—§ä»£ç :
        # self.vision_encoder = VisionEncoder(...)
        
        # æ–°ä»£ç :
        self.vision_encoder = ImprovedVisionEncoder(
            img_size=config.get('img_size', 384),
            patch_size=config.get('patch_size', 14),
            embed_dim=config.get('vision_embed_dim', 1152),
            depth=config.get('vision_depth', 27),
            num_heads=config.get('vision_heads', 16),
            use_flash_attn=True,  # å¯ç”¨Flash Attention
            qkv_bias=True
        )
        
        # æ›¿æ¢æŠ•å½±å±‚
        # æ—§ä»£ç :
        # self.vision_projection = nn.Linear(...)
        
        # æ–°ä»£ç :
        self.vision_projector = ImprovedProjector(
            input_dim=config.get('vision_embed_dim', 1152),
            output_dim=config.get('llm_hidden_size', 4096),
            projector_type='token_pooling',  # ä½¿ç”¨token pooling
            pooling_kernel=2  # å‡å°‘4å€tokenæ•°é‡
        )
        
        # å…¶ä½™ä»£ç ä¿æŒä¸å˜...
```

#### âœ… ä»»åŠ¡2: æµ‹è¯•æ–°ç»„ä»¶

```bash
# åˆ›å»ºæµ‹è¯•è„šæœ¬
cd D:\OpenMind
python -c "
import torch
from src.improved_vision_encoder import ImprovedVisionEncoder, ImprovedProjector

# æµ‹è¯•ç¼–ç å™¨
encoder = ImprovedVisionEncoder(
    img_size=384,
    embed_dim=1152,
    depth=27,
    use_flash_attn=True
)

# æµ‹è¯•è¾“å…¥
x = torch.randn(2, 3, 384, 384)
features = encoder(x)
print(f'Vision features shape: {features.shape}')

# æµ‹è¯•æŠ•å½±å™¨
projector = ImprovedProjector(
    input_dim=1152,
    output_dim=4096,
    projector_type='token_pooling'
)

projected = projector(features)
print(f'Projected shape: {projected.shape}')
print('âœ… æ–°ç»„ä»¶æµ‹è¯•é€šè¿‡ï¼')
"
```

é¢„æœŸè¾“å‡º:
```
Vision features shape: torch.Size([2, 729, 1152])
Projected shape: torch.Size([2, 182, 4096])
âœ… æ–°ç»„ä»¶æµ‹è¯•é€šè¿‡ï¼
```

### Day 3-4: å®Œå–„è®­ç»ƒå¾ªç¯

#### âœ… ä»»åŠ¡3: å‡çº§è®­ç»ƒå™¨

åˆ›å»ºæ–°æ–‡ä»¶ `src/production_trainer.py`:

```python
# src/production_trainer.py
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from transformers import get_cosine_schedule_with_warmup
import wandb
from tqdm import tqdm
import logging

logger = logging.getLogger(__name__)

class ProductionTrainer:
    """å·¥ç¨‹çº§è®­ç»ƒå™¨ - ç¨³å®šæ€§å’Œç›‘æ§å¢å¼º"""
    
    def __init__(self, model, config):
        self.model = model
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=config['learning_rate'],
            weight_decay=config['weight_decay'],
            betas=(0.9, 0.95)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler = get_cosine_schedule_with_warmup(
            self.optimizer,
            num_warmup_steps=config['warmup_steps'],
            num_training_steps=config['total_steps']
        )
        
        # æ··åˆç²¾åº¦
        self.scaler = torch.cuda.amp.GradScaler() if config.get('use_amp', True) else None
        
        # ç›‘æ§
        self.loss_history = []
        self.best_loss = float('inf')
        self.patience_counter = 0
        
        # æ¢¯åº¦ç´¯ç§¯
        self.gradient_accumulation_steps = config.get('gradient_accumulation', 4)
        
    def train_epoch(self, dataloader, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        step = 0
        
        pbar = tqdm(dataloader, desc=f'Epoch {epoch}')
        
        for batch_idx, batch in enumerate(pbar):
            # ç§»åŠ¨æ•°æ®åˆ°GPU
            batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                    for k, v in batch.items()}
            
            # å‰å‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰
            if self.scaler:
                with torch.cuda.amp.autocast():
                    outputs = self.model(**batch)
                    loss = outputs['loss'] / self.gradient_accumulation_steps
            else:
                outputs = self.model(**batch)
                loss = outputs['loss'] / self.gradient_accumulation_steps
            
            # åå‘ä¼ æ’­
            if self.scaler:
                self.scaler.scale(loss).backward()
            else:
                loss.backward()
            
            # æ¢¯åº¦ç´¯ç§¯
            if (batch_idx + 1) % self.gradient_accumulation_steps == 0:
                # æ¢¯åº¦è£å‰ª
                if self.scaler:
                    self.scaler.unscale_(self.optimizer)
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                
                # æ£€æŸ¥æ¢¯åº¦å¼‚å¸¸
                if self._check_gradients():
                    # ä¼˜åŒ–å™¨æ­¥éª¤
                    if self.scaler:
                        self.scaler.step(self.optimizer)
                        self.scaler.update()
                    else:
                        self.optimizer.step()
                    
                    self.scheduler.step()
                    self.optimizer.zero_grad()
                    step += 1
                else:
                    logger.warning(f"Skipping step {step} due to abnormal gradients")
                    self.optimizer.zero_grad()
            
            # è®°å½•
            total_loss += loss.item() * self.gradient_accumulation_steps
            current_loss = total_loss / (batch_idx + 1)
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f'{current_loss:.4f}',
                'lr': f'{self.scheduler.get_last_lr()[0]:.2e}'
            })
            
            # Losså¼‚å¸¸æ£€æµ‹
            if self._detect_loss_spike(loss.item()):
                logger.error(f"Loss spike detected at step {step}! Current: {loss.item():.4f}")
                # å¯ä»¥é€‰æ‹©å›æ»šåˆ°ä¸Šä¸€ä¸ªcheckpoint
            
            # å®šæœŸä¿å­˜
            if step % self.config.get('save_steps', 1000) == 0:
                self.save_checkpoint(epoch, step, current_loss)
        
        return total_loss / len(dataloader)
    
    def _check_gradients(self):
        """æ£€æŸ¥æ¢¯åº¦æ˜¯å¦æ­£å¸¸"""
        total_norm = 0
        for p in self.model.parameters():
            if p.grad is not None:
                param_norm = p.grad.data.norm(2)
                total_norm += param_norm.item() ** 2
        total_norm = total_norm ** 0.5
        
        # æ£€æŸ¥NaNæˆ–è¿‡å¤§çš„æ¢¯åº¦
        if torch.isnan(torch.tensor(total_norm)) or total_norm > 1000:
            return False
        return True
    
    def _detect_loss_spike(self, current_loss):
        """æ£€æµ‹Lossçªç„¶é£™å‡"""
        self.loss_history.append(current_loss)
        if len(self.loss_history) < 10:
            return False
        
        recent_avg = sum(self.loss_history[-10:]) / 10
        if current_loss > recent_avg * 2.0:
            return True
        return False
    
    def save_checkpoint(self, epoch, step, loss):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'step': step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'loss': loss,
            'config': self.config
        }
        
        path = f"{self.config['output_dir']}/checkpoint-epoch{epoch}-step{step}.pt"
        torch.save(checkpoint, path)
        logger.info(f"Checkpoint saved to {path}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if loss < self.best_loss:
            self.best_loss = loss
            best_path = f"{self.config['output_dir']}/best_model.pt"
            torch.save(checkpoint, best_path)
            logger.info(f"Best model updated: loss={loss:.4f}")
```

#### âœ… ä»»åŠ¡4: åˆ›å»ºè®­ç»ƒè„šæœ¬

åˆ›å»º `scripts/train_week1.py`:

```python
# scripts/train_week1.py
import torch
import yaml
from pathlib import Path
import sys

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent / 'src'))

from model_architecture import MultimodalReasoningModel
from production_trainer import ProductionTrainer
from data_pipeline import MultimodalDataset, collate_fn

def main():
    # 1. åŠ è½½é…ç½®
    with open('configs/training_config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # 2. åˆ›å»ºæ¨¡å‹
    print("Creating model...")
    model_config = {
        'img_size': 384,
        'vision_embed_dim': 1152,
        'vision_depth': 27,
        'vision_heads': 16,
        'llm_hidden_size': 4096,
        'llm_model_name': config['model']['language_model']
    }
    
    model = MultimodalReasoningModel(model_config)
    model = model.cuda()
    
    print(f"Model created. Parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # 3. åŠ è½½æ•°æ®
    print("Loading data...")
    train_dataset = MultimodalDataset(
        data_path=config['data']['pretrain_data'],
        image_processor=model.vision_encoder.image_processor,
        tokenizer=model.tokenizer,
        max_length=config['training']['max_length']
    )
    
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=4,
        collate_fn=collate_fn
    )
    
    print(f"Dataset loaded. Size: {len(train_dataset)}")
    
    # 4. åˆ›å»ºè®­ç»ƒå™¨
    trainer_config = {
        'learning_rate': config['optimizer']['learning_rate'],
        'weight_decay': config['optimizer']['weight_decay'],
        'warmup_steps': config['training']['warmup_steps'],
        'total_steps': len(train_loader) * config['training']['num_epochs'],
        'gradient_accumulation': config['training']['gradient_accumulation'],
        'use_amp': config['training']['mixed_precision'],
        'output_dir': config['training']['output_dir'],
        'save_steps': 500
    }
    
    trainer = ProductionTrainer(model, trainer_config)
    
    # 5. å¼€å§‹è®­ç»ƒ
    print("Starting training...")
    for epoch in range(config['training']['num_epochs']):
        avg_loss = trainer.train_epoch(train_loader, epoch)
        print(f"Epoch {epoch} completed. Average loss: {avg_loss:.4f}")

if __name__ == '__main__':
    main()
```

### Day 5-6: æ•°æ®å‡†å¤‡å’ŒéªŒè¯

#### âœ… ä»»åŠ¡5: ä¸‹è½½åŸºç¡€æ•°æ®

```bash
# åˆ›å»ºæ•°æ®ä¸‹è½½è„šæœ¬
# scripts/download_base_data.py
```

```python
# scripts/download_base_data.py
from datasets import load_dataset
import json
from pathlib import Path

def download_coco_subset():
    """ä¸‹è½½COCOå­é›†ç”¨äºåˆæ­¥éªŒè¯"""
    print("Downloading COCO captions...")
    dataset = load_dataset("HuggingFaceM4/COCO", split="train[:1000]")
    
    # è½¬æ¢ä¸ºJSONLæ ¼å¼
    output_path = Path("data/pretrain_small.jsonl")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w') as f:
        for item in dataset:
            sample = {
                'image': item['image_path'],
                'text': item['caption']
            }
            f.write(json.dumps(sample) + '\n')
    
    print(f"Saved {len(dataset)} samples to {output_path}")

def download_vqa_subset():
    """ä¸‹è½½VQAå­é›†"""
    print("Downloading VQA...")
    dataset = load_dataset("HuggingFaceM4/VQAv2", split="train[:500]")
    
    output_path = Path("data/sft_small.jsonl")
    with open(output_path, 'w') as f:
        for item in dataset:
            sample = {
                'image': item['image_path'],
                'question': item['question'],
                'answer': item['answer']
            }
            f.write(json.dumps(sample) + '\n')
    
    print(f"Saved {len(dataset)} samples to {output_path}")

if __name__ == '__main__':
    download_coco_subset()
    download_vqa_subset()
```

è¿è¡Œ:
```bash
python scripts/download_base_data.py
```

#### âœ… ä»»åŠ¡6: ç¬¬ä¸€æ¬¡è®­ç»ƒæµ‹è¯•

```bash
# å°è§„æ¨¡æµ‹è¯•è®­ç»ƒï¼ˆç¡®ä¿ä¸€åˆ‡æ­£å¸¸ï¼‰
python scripts/train_week1.py
```

é¢„æœŸè¾“å‡º:
```
Creating model...
Model created. Parameters: 8,234,567,890
Loading data...
Dataset loaded. Size: 1000
Starting training...
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [05:23<00:00, loss=2.3456, lr=1.2e-5]
Epoch 0 completed. Average loss: 2.3456
âœ… è®­ç»ƒæˆåŠŸï¼
```

### Day 7: åŸºç¡€è¯„ä¼°

#### âœ… ä»»åŠ¡7: è¿è¡Œbaselineè¯„ä¼°

```bash
# åˆ›å»ºç®€å•è¯„ä¼°è„šæœ¬
# scripts/eval_week1.py
```

```python
# scripts/eval_week1.py
import torch
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).parent.parent / 'src'))

from model_architecture import MultimodalReasoningModel
from PIL import Image

def simple_inference_test():
    """ç®€å•çš„æ¨ç†æµ‹è¯•"""
    # åŠ è½½æ¨¡å‹
    model = MultimodalReasoningModel.from_pretrained('outputs/best_model.pt')
    model = model.cuda()
    model.eval()
    
    # æµ‹è¯•å›¾åƒç†è§£
    test_image = Image.open('data/test_images/sample.jpg')
    question = "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"
    
    with torch.no_grad():
        response = model.generate(
            images=[test_image],
            prompt=question,
            max_length=100
        )
    
    print(f"Question: {question}")
    print(f"Answer: {response}")
    
    return response

if __name__ == '__main__':
    simple_inference_test()
```

---

## ğŸ“… Week 1 æ—¶é—´è¡¨

| æ—¥æœŸ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ | æ£€æŸ¥ç‚¹ |
|------|------|---------|--------|
| Day 1 | é›†æˆæ”¹è¿›è§†è§‰ç¼–ç å™¨ | 4å°æ—¶ | âœ… ç»„ä»¶æµ‹è¯•é€šè¿‡ |
| Day 2 | ä¿®æ”¹ä¸»æ¨¡å‹æ¶æ„ | 4å°æ—¶ | âœ… æ¨¡å‹åŠ è½½æˆåŠŸ |
| Day 3 | åˆ›å»ºProductionTrainer | 6å°æ—¶ | âœ… è®­ç»ƒå™¨æµ‹è¯•é€šè¿‡ |
| Day 4 | å®Œå–„è®­ç»ƒè„šæœ¬ | 4å°æ—¶ | âœ… è„šæœ¬å¯è¿è¡Œ |
| Day 5 | ä¸‹è½½å’Œå‡†å¤‡æ•°æ® | 3å°æ—¶ | âœ… æ•°æ®å‡†å¤‡å®Œæˆ |
| Day 6 | ç¬¬ä¸€æ¬¡è®­ç»ƒ | 6å°æ—¶ | âœ… è®­ç»ƒç¨³å®šè¿è¡Œ |
| Day 7 | åŸºç¡€è¯„ä¼° | 3å°æ—¶ | âœ… æ¨ç†æµ‹è¯•é€šè¿‡ |

---

## âœ… Week 1 æˆåŠŸæ ‡å‡†

å®Œæˆä»¥ä¸‹æ‰€æœ‰é¡¹ç›®å³ä¸ºæˆåŠŸ:

- [ ] æ”¹è¿›çš„è§†è§‰ç¼–ç å™¨é›†æˆå®Œæˆ
- [ ] ProductionTraineråˆ›å»ºå¹¶æµ‹è¯•é€šè¿‡
- [ ] åœ¨1000æ ·æœ¬ä¸Šå®Œæˆ1ä¸ªepochè®­ç»ƒ
- [ ] Lossæ­£å¸¸ä¸‹é™ï¼ˆä¸å‡ºç°NaNæˆ–çˆ†ç‚¸ï¼‰
- [ ] å¯ä»¥æ­£å¸¸ä¿å­˜å’ŒåŠ è½½checkpoint
- [ ] ç®€å•æ¨ç†æµ‹è¯•å¯ä»¥ç”Ÿæˆæ–‡æœ¬
- [ ] æ˜¾å­˜å ç”¨ < 40GB (å•å¡A100å¯è¿è¡Œ)

---

## ğŸš¨ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜1: CUDA Out of Memory

```python
# è§£å†³æ–¹æ¡ˆ
# 1. å‡å°batch size
config['training']['batch_size'] = 1

# 2. å¯ç”¨æ¢¯åº¦ç´¯ç§¯
config['training']['gradient_accumulation'] = 8

# 3. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.gradient_checkpointing_enable()

# 4. ä½¿ç”¨Flash Attentionï¼ˆå·²é»˜è®¤å¼€å¯ï¼‰
```

### é—®é¢˜2: Lossä¸ä¸‹é™

```python
# æ£€æŸ¥åˆ—è¡¨
# 1. å­¦ä¹ ç‡æ˜¯å¦å¤ªå°ï¼Ÿ
config['optimizer']['learning_rate'] = 2e-5  # è°ƒå¤§

# 2. æ•°æ®æ˜¯å¦æ­£ç¡®ï¼Ÿ
# è¿è¡Œ: python scripts/test_data_pipeline.py

# 3. æ¨¡å‹æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–ï¼Ÿ
# æ£€æŸ¥: æ‰“å°å‰å‡ ä¸ªbatchçš„loss
```

### é—®é¢˜3: è®­ç»ƒé€Ÿåº¦æ…¢

```python
# ä¼˜åŒ–æ–¹æ¡ˆ
# 1. å¯ç”¨æ··åˆç²¾åº¦
config['training']['mixed_precision'] = True

# 2. å¢åŠ num_workers
dataloader = DataLoader(..., num_workers=8)

# 3. ä½¿ç”¨æ›´å¤§çš„batch size + æ¢¯åº¦ç´¯ç§¯
```

---

## ğŸ“Š Week 1 é¢„æœŸç»“æœ

å®ŒæˆWeek 1åï¼Œä½ åº”è¯¥æœ‰:

1. **ä»£ç å±‚é¢**:
   - âœ… é›†æˆäº†æ”¹è¿›çš„è§†è§‰ç¼–ç å™¨
   - âœ… ç¨³å®šçš„è®­ç»ƒå¾ªç¯
   - âœ… å®Œæ•´çš„checkpointç®¡ç†

2. **æ¨¡å‹å±‚é¢**:
   - âœ… å¯ä»¥åŠ è½½å’Œè¿è¡Œçš„æ¨¡å‹
   - âœ… åœ¨å°æ•°æ®é›†ä¸ŠLossæ­£å¸¸ä¸‹é™
   - âœ… å¯ä»¥ç”ŸæˆåŸºç¡€çš„å›¾æ–‡å“åº”

3. **åŸºç¡€è®¾æ–½**:
   - âœ… æ•°æ®åŠ è½½pipeline
   - âœ… è®­ç»ƒç›‘æ§å’Œæ—¥å¿—
   - âœ… æ¨¡å‹ä¿å­˜å’ŒåŠ è½½

---

## ğŸ¯ ä¸‹å‘¨é¢„å‘Š (Week 2)

Week 2 å°†focus on:
- æ‰©å¤§è®­ç»ƒæ•°æ®é‡ï¼ˆ10ä¸‡+ æ ·æœ¬ï¼‰
- å®Œæ•´çš„benchmarkè¯„ä¼°
- æ€§èƒ½ä¼˜åŒ–å’Œè°ƒä¼˜
- å‡†å¤‡è¿›å…¥Week 3çš„é•¿æ–‡æœ¬èƒ½åŠ›å¼€å‘

---

## ğŸ’¡ ç«‹å³å¼€å§‹

```bash
# ç°åœ¨å°±æ‰§è¡Œè¿™äº›å‘½ä»¤ï¼

# 1. æµ‹è¯•æ”¹è¿›çš„ç»„ä»¶
cd D:\OpenMind
python src\improved_vision_encoder.py

# 2. å¦‚æœæµ‹è¯•é€šè¿‡ï¼Œå¼€å§‹é›†æˆ
code src\model_architecture.py
# æŒ‰ç…§ä¸Šé¢çš„æŒ‡å¼•ä¿®æ”¹ä»£ç 

# 3. åˆ›å»ºè®­ç»ƒå™¨
code src\production_trainer.py
# å¤åˆ¶ä¸Šé¢çš„ä»£ç 

# 4. å‡†å¤‡æ•°æ®
python scripts\download_base_data.py

# 5. å¼€å§‹è®­ç»ƒï¼
python scripts\train_week1.py
```

**ç¬¬ä¸€å‘¨æœ€é‡è¦çš„æ˜¯ï¼šè®©è®­ç»ƒè·‘èµ·æ¥å¹¶ç¨³å®šè¿è¡Œï¼** ğŸš€

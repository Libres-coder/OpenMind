# å¤šæ¨¡æ€æ¨¡å‹å¼€å‘è·¯çº¿å›¾ ğŸ—ºï¸

> **å½“å‰çŠ¶æ€**: å·²å®ŒæˆæŠ€æœ¯æ–¹æ¡ˆè®¾è®¡å’Œä»£ç æ¡†æ¶
> 
> **ä¸‹ä¸€æ­¥**: å¼€å§‹å®æ–½å¼€å‘

---

## ğŸ“… å®Œæ•´å¼€å‘æ—¶é—´çº¿ï¼ˆ16å‘¨ï¼‰

```
ç¬¬1å‘¨   âœ… ç¯å¢ƒæ­å»º â†’ åŸºç¡€éªŒè¯ â†’ å•å…ƒæµ‹è¯•
ç¬¬2-3å‘¨ ğŸ“¦ æ•°æ®ä¸‹è½½ â†’ æ•°æ®å¤„ç† â†’ PipelineéªŒè¯
ç¬¬4-5å‘¨ ğŸ§ª æ¨¡å‹æµ‹è¯• â†’ å°è§„æ¨¡è®­ç»ƒ â†’ Debugä¼˜åŒ–
ç¬¬6-8å‘¨ ğŸš€ é¢„è®­ç»ƒå¯åŠ¨ â†’ æŒç»­ç›‘æ§ â†’ æ£€æŸ¥ç‚¹ç®¡ç†
ç¬¬9-12å‘¨ ğŸ¯ æŒ‡ä»¤å¾®è°ƒ â†’ èƒ½åŠ›æå‡ â†’ æ€§èƒ½è°ƒä¼˜
ç¬¬13-16å‘¨ ğŸ“Š å…¨é¢è¯„ä¼° â†’ æ¨¡å‹ä¼˜åŒ– â†’ éƒ¨ç½²ä¸Šçº¿
```

---

## ğŸ¯ ç¬¬1å‘¨ï¼šç¯å¢ƒæ­å»ºä¸éªŒè¯ï¼ˆç«‹å³å¼€å§‹ï¼‰

### Day 1-2: ç¯å¢ƒé…ç½®

#### 1.1 å®‰è£…ä¾èµ–ï¼ˆWindowsï¼‰

```powershell
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
.\venv\Scripts\activate

# å‡çº§pip
python -m pip install --upgrade pip

# å®‰è£…PyTorch (CUDA 12.1)
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install transformers==4.36.0 accelerate==0.25.0 datasets==2.16.0

# å®‰è£…è®­ç»ƒå·¥å…·ï¼ˆå¯é€‰ï¼‰
pip install deepspeed
pip install flash-attn --no-build-isolation  # éœ€è¦CUDAå’Œç¼–è¯‘ç¯å¢ƒ

# å®‰è£…æ•°æ®å¤„ç†
pip install webdataset pillow requests tqdm pyyaml

# å®‰è£…è¯„ä¼°å·¥å…·
pip install scikit-learn nltk rouge-score wandb tensorboard
```

#### 1.2 éªŒè¯å®‰è£…

åˆ›å»ºéªŒè¯è„šæœ¬ï¼š

```python
# scripts/verify_environment.py
import sys
import torch
import transformers
import accelerate

print("="*50)
print("ç¯å¢ƒéªŒè¯")
print("="*50)

print(f"\nPythonç‰ˆæœ¬: {sys.version}")
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"Transformersç‰ˆæœ¬: {transformers.__version__}")
print(f"Accelerateç‰ˆæœ¬: {accelerate.__version__}")

print(f"\nCUDAå¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"    æ˜¾å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB")

print("\nâœ… ç¯å¢ƒéªŒè¯å®Œæˆï¼")
```

è¿è¡ŒéªŒè¯ï¼š
```bash
python scripts/verify_environment.py
```

### Day 3-4: æµ‹è¯•æ¨¡å‹åŠ è½½

#### 1.3 ä¸‹è½½åŸºç¡€æ¨¡å‹

```python
# scripts/download_base_model.py
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen2-7B"  # æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹æµ‹è¯•
print(f"ä¸‹è½½æ¨¡å‹: {model_name}")

# ä¸‹è½½tokenizer
tokenizer = AutoTokenizer.from_pretrained(
    model_name,
    trust_remote_code=True
)
tokenizer.save_pretrained("./models/qwen2-7b")

# ä¸‹è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼šå…ˆåªä¸‹è½½é…ç½®ï¼‰
from transformers import AutoConfig
config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)
config.save_pretrained("./models/qwen2-7b")

print("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ")
```

#### 1.4 æµ‹è¯•æ¨¡å‹æ¶æ„

```python
# scripts/test_model_architecture.py
import torch
from src.model_architecture import create_model

print("æµ‹è¯•æ¨¡å‹æ¶æ„...")

config = {
    'base_model': './models/qwen2-7b',  # ä½¿ç”¨æœ¬åœ°è·¯å¾„
    'vision_model': 'openai/clip-vit-large-patch14',
    'freeze_vision': True,
    'perceiver_depth': 2,  # å‡å°æµ‹è¯•
    'num_latents': 32,     # å‡å°æµ‹è¯•
    'enable_audio': False,
    'enable_cot': True,
    'enable_verification': True
}

try:
    model = create_model(config)
    print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    # æ‰“å°å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"æ€»å‚æ•°: {total_params/1e9:.2f}B")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params/1e9:.2f}B")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 2
    seq_len = 128
    
    input_ids = torch.randint(0, 1000, (batch_size, seq_len))
    attention_mask = torch.ones_like(input_ids)
    
    print("\næµ‹è¯•å‰å‘ä¼ æ’­...")
    with torch.no_grad():
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
    
    print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºshape: {outputs['logits'].shape}")
    
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
```

### Day 5-7: æ•°æ®å‡†å¤‡åŸºç¡€

#### 1.5 åˆ›å»ºç¤ºä¾‹æ•°æ®é›†

```python
# scripts/create_sample_data.py
import json
import os
from pathlib import Path

def create_sample_pretrain_data():
    """åˆ›å»ºé¢„è®­ç»ƒç¤ºä¾‹æ•°æ®"""
    output_dir = Path("data/sample/pretrain")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    samples = []
    for i in range(100):  # åˆ›å»º100ä¸ªç¤ºä¾‹
        sample = {
            "text": f"è¿™æ˜¯ç¬¬{i}ä¸ªè®­ç»ƒæ ·æœ¬ã€‚åŒ…å«å¤šæ¨¡æ€å†…å®¹çš„æè¿°æ–‡æœ¬ã€‚",
            "metadata": {
                "source": "sample",
                "id": i
            }
        }
        samples.append(sample)
    
    # ä¿å­˜ä¸ºJSONL
    with open(output_dir / "train.jsonl", 'w', encoding='utf-8') as f:
        for sample in samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    print(f"âœ… åˆ›å»ºäº† {len(samples)} ä¸ªé¢„è®­ç»ƒæ ·æœ¬")

def create_sample_sft_data():
    """åˆ›å»ºæŒ‡ä»¤å¾®è°ƒç¤ºä¾‹æ•°æ®"""
    output_dir = Path("data/sample/sft")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    samples = [
        {
            "conversations": [
                {"from": "user", "value": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"},
                {"from": "assistant", "value": "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€AIåŠ©æ‰‹ï¼Œå¯ä»¥å¤„ç†æ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘ç­‰å¤šç§è¾“å…¥ã€‚"}
            ]
        },
        {
            "conversations": [
                {"from": "user", "value": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"},
                {"from": "assistant", "value": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶æ”¹è¿›ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚"}
            ]
        }
    ] * 50  # å¤åˆ¶50æ¬¡ä½œä¸ºç¤ºä¾‹
    
    with open(output_dir / "train.jsonl", 'w', encoding='utf-8') as f:
        for sample in samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    print(f"âœ… åˆ›å»ºäº† {len(samples)} ä¸ªSFTæ ·æœ¬")

if __name__ == "__main__":
    create_sample_pretrain_data()
    create_sample_sft_data()
    print("\nâœ… ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆ")
```

#### 1.6 æµ‹è¯•æ•°æ®åŠ è½½

```python
# scripts/test_data_pipeline.py
from src.data_pipeline import create_dataloader

print("æµ‹è¯•æ•°æ®åŠ è½½...")

try:
    dataloader = create_dataloader(
        data_path="data/sample/pretrain/train.jsonl",
        tokenizer_name="Qwen/Qwen2-7B",
        batch_size=2,
        num_workers=0,  # Windowsä¸Šè®¾ä¸º0
        shuffle=False
    )
    
    # æµ‹è¯•åŠ è½½ä¸€ä¸ªbatch
    for batch in dataloader:
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  input_ids shape: {batch['input_ids'].shape}")
        print(f"  attention_mask shape: {batch['attention_mask'].shape}")
        print(f"  labels shape: {batch['labels'].shape}")
        break
    
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
```

---

## ğŸ“¦ ç¬¬2-3å‘¨ï¼šæ•°æ®å‡†å¤‡ï¼ˆæ ¸å¿ƒä»»åŠ¡ï¼‰

### 2.1 çœŸå®æ•°æ®ä¸‹è½½ç­–ç•¥

#### é€‰é¡¹A: å°è§„æ¨¡å¿«é€ŸéªŒè¯ï¼ˆæ¨èå…ˆåšï¼‰

```python
# scripts/download_small_datasets.py
"""
ä¸‹è½½å°è§„æ¨¡æ•°æ®é›†ç”¨äºå¿«é€ŸéªŒè¯
- COCO 2017 éªŒè¯é›†: ~5GB
- CC3M å­é›†: ~10GB
"""
import os
from datasets import load_dataset

def download_coco_val():
    """ä¸‹è½½COCOéªŒè¯é›†"""
    print("ä¸‹è½½COCOéªŒè¯é›†...")
    dataset = load_dataset("HuggingFaceM4/COCO", split="validation")
    dataset.save_to_disk("data/coco_val")
    print(f"âœ… ä¸‹è½½å®Œæˆ: {len(dataset)} æ ·æœ¬")

def download_cc3m_subset():
    """ä¸‹è½½CC3Må­é›†"""
    print("ä¸‹è½½CC3Må­é›†...")
    dataset = load_dataset("conceptual_captions", split="train[:10000]")
    dataset.save_to_disk("data/cc3m_subset")
    print(f"âœ… ä¸‹è½½å®Œæˆ: {len(dataset)} æ ·æœ¬")

if __name__ == "__main__":
    os.makedirs("data", exist_ok=True)
    download_coco_val()
    download_cc3m_subset()
```

#### é€‰é¡¹B: å¤§è§„æ¨¡æ•°æ®å‡†å¤‡ï¼ˆæ­£å¼è®­ç»ƒï¼‰

å‚è€ƒæ–‡æ¡£ä¸­çš„æ•°æ®é›†æ¸…å•ï¼Œä½¿ç”¨ `img2dataset` ä¸‹è½½LAIONç­‰å¤§è§„æ¨¡æ•°æ®ã€‚

### 2.2 æ•°æ®é¢„å¤„ç†Pipeline

```python
# scripts/preprocess_data.py
"""
ç»Ÿä¸€æ•°æ®é¢„å¤„ç†è„šæœ¬
"""
from pathlib import Path
import json
from PIL import Image
from tqdm import tqdm
from datasets import load_from_disk

def preprocess_coco_for_training(input_dir, output_file):
    """å°†COCOæ ¼å¼è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼"""
    dataset = load_from_disk(input_dir)
    
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for item in tqdm(dataset, desc="å¤„ç†COCOæ•°æ®"):
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            sample = {
                "text": item['caption'],
                "image": item['image_path'],  # éœ€è¦ä¿å­˜å›¾åƒè·¯å¾„
                "metadata": {
                    "source": "coco",
                    "image_id": item.get('image_id')
                }
            }
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    print(f"âœ… é¢„å¤„ç†å®Œæˆ: {output_file}")

if __name__ == "__main__":
    preprocess_coco_for_training(
        "data/coco_val",
        "data/processed/pretrain_coco.jsonl"
    )
```

---

## ğŸ§ª ç¬¬4-5å‘¨ï¼šæ¨¡å‹è®­ç»ƒéªŒè¯

### 3.1 è¶…å°è§„æ¨¡è®­ç»ƒæµ‹è¯•ï¼ˆ2-4å°æ—¶ï¼‰

```bash
# ç›®çš„ï¼šéªŒè¯æ•´ä¸ªè®­ç»ƒæµç¨‹æ²¡æœ‰bug
python src/train_multimodal.py \
    --config configs/training_config.yaml \
    --stage pretrain \
    --num_epochs 1 \
    --batch_size 1 \
    --gradient_accumulation_steps 2 \
    --max_steps 50 \
    --output_dir checkpoints/test_run
```

é¢„æœŸç»“æœï¼š
- âœ… è®­ç»ƒæ­£å¸¸è¿è¡Œ
- âœ… Lossä¸‹é™
- âœ… æ£€æŸ¥ç‚¹æ­£å¸¸ä¿å­˜
- âœ… æ˜¾å­˜å ç”¨æ­£å¸¸

### 3.2 å°è§„æ¨¡å®Œæ•´è®­ç»ƒï¼ˆ1-2å¤©ï¼‰

```bash
# ä½¿ç”¨ç¤ºä¾‹æ•°æ®é›†å®Œæ•´è®­ç»ƒ1ä¸ªepoch
python src/train_multimodal.py \
    --config configs/training_config.yaml \
    --stage pretrain \
    --num_epochs 3 \
    --batch_size 2 \
    --output_dir checkpoints/small_scale
```

### 3.3 è®­ç»ƒç›‘æ§å’Œè°ƒè¯•

åˆ›å»ºç›‘æ§è„šæœ¬ï¼š

```python
# scripts/monitor_training.py
"""
å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦
"""
import json
from pathlib import Path
import time

def monitor_checkpoints(checkpoint_dir):
    checkpoint_dir = Path(checkpoint_dir)
    
    while True:
        checkpoints = sorted(checkpoint_dir.glob("checkpoint-*"))
        
        if checkpoints:
            latest = checkpoints[-1]
            metrics_file = latest / "metrics.json"
            
            if metrics_file.exists():
                with open(metrics_file) as f:
                    metrics = json.load(f)
                
                print(f"\næœ€æ–°æ£€æŸ¥ç‚¹: {latest.name}")
                print(f"Epoch: {metrics.get('epoch')}")
                print(f"Train Loss: {metrics.get('train_loss', 'N/A')}")
                print(f"æ—¶é—´: {metrics.get('timestamp')}")
        
        time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

if __name__ == "__main__":
    monitor_checkpoints("checkpoints/small_scale")
```

---

## ğŸš€ ç¬¬6-8å‘¨ï¼šå¤šæ¨¡æ€é¢„è®­ç»ƒ

### 4.1 é…ç½®ä¼˜åŒ–

æ ¹æ®ä½ çš„ç¡¬ä»¶é…ç½®è°ƒæ•´ `configs/training_config.yaml`:

```yaml
# 4x RTX 4090 é…ç½®ç¤ºä¾‹
training:
  batch_size: 2                    # æ¯GPUæ‰¹æ¬¡
  gradient_accumulation_steps: 8   # æœ‰æ•ˆbatch_size=64
  learning_rate: 2.0e-5
  mixed_precision: "bf16"
  use_gradient_checkpointing: true
  
  num_epochs:
    pretrain: 10
```

### 4.2 å¯åŠ¨é¢„è®­ç»ƒ

```bash
# å•GPUè®­ç»ƒ
python src/train_multimodal.py \
    --config configs/training_config.yaml \
    --stage pretrain

# å¤šGPUè®­ç»ƒ (ä½¿ç”¨Accelerate)
accelerate launch --multi_gpu --num_processes=4 \
    src/train_multimodal.py \
    --config configs/training_config.yaml \
    --stage pretrain
```

### 4.3 æŒç»­ç›‘æ§

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir logs/

# æˆ–å¯åŠ¨Wandbï¼ˆéœ€è¦å…ˆç™»å½•ï¼‰
wandb login
# ç„¶ååœ¨é…ç½®ä¸­å¯ç”¨: use_wandb: true
```

---

## ğŸ¯ ç¬¬9-12å‘¨ï¼šæŒ‡ä»¤å¾®è°ƒ

### 5.1 å‡†å¤‡SFTæ•°æ®

æ¨èæ•°æ®æºï¼š
- ShareGPTå¯¹è¯æ•°æ®
- LLaVA-Instructè§†è§‰æŒ‡ä»¤
- è‡ªå»ºé«˜è´¨é‡æ•°æ®ï¼ˆæœ€é‡è¦ï¼‰

### 5.2 å¯åŠ¨SFTè®­ç»ƒ

```bash
python src/train_multimodal.py \
    --config configs/training_config.yaml \
    --stage sft \
    --resume_from_checkpoint checkpoints/pretrain/checkpoint-epoch-10
```

---

## ğŸ“Š ç¬¬13-16å‘¨ï¼šè¯„ä¼°å’Œä¼˜åŒ–

### 6.1 å…¨é¢è¯„ä¼°

```bash
python src/evaluate_model.py \
    --model_config configs/model_config.yaml \
    --checkpoint checkpoints/sft/best_model.pt \
    --eval_config configs/eval_config.yaml
```

### 6.2 æ¨¡å‹é‡åŒ–ï¼ˆå¯é€‰ï¼‰

```python
# scripts/quantize_model.py
from transformers import AutoModelForCausalLM
import torch

model = AutoModelForCausalLM.from_pretrained(
    "checkpoints/sft/best_model",
    device_map="auto",
    load_in_8bit=True  # INT8é‡åŒ–
)

model.save_pretrained("checkpoints/quantized_int8")
```

---

## ğŸ› ï¸ å¼€å‘æœ€ä½³å®è·µ

### 1. ç‰ˆæœ¬æ§åˆ¶

```bash
git init
git add .
git commit -m "Initial commit: å¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒæ¡†æ¶"

# åˆ›å»ºå¼€å‘åˆ†æ”¯
git checkout -b feature/data-pipeline
```

### 2. å®éªŒè®°å½•

åˆ›å»ºå®éªŒæ—¥å¿—ï¼š

```python
# experiments/exp_log.md
## å®éªŒ1: åŸºç¡€æ¶æ„éªŒè¯
- æ—¥æœŸ: 2025-01-XX
- é…ç½®: Qwen2-7B + CLIP
- æ•°æ®: COCO val 5K
- ç»“æœ: Lossä»8.5é™åˆ°6.2
- é—®é¢˜: æ˜¾å­˜å ç”¨è¿‡é«˜
- è§£å†³: å¯ç”¨gradient_checkpointing
```

### 3. å®šæœŸæ£€æŸ¥ç‚¹

```python
# æ¯å¤©å¤‡ä»½é‡è¦æ£€æŸ¥ç‚¹
import shutil
from datetime import datetime

checkpoint_dir = "checkpoints/pretrain/checkpoint-epoch-5"
backup_dir = f"backups/{datetime.now().strftime('%Y%m%d')}"
shutil.copytree(checkpoint_dir, backup_dir)
```

---

## âš ï¸ å¸¸è§é—®é¢˜é¢„é˜²

### é—®é¢˜1: CUDA Out of Memory

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å‡å°batch_size
batch_size: 1
gradient_accumulation_steps: 16

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
use_gradient_checkpointing: true

# å†»ç»“è§†è§‰ç¼–ç å™¨
freeze_vision: true
```

### é—®é¢˜2: è®­ç»ƒé€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**:
- ä½¿ç”¨æ›´å¿«çš„æ•°æ®åŠ è½½å™¨ (WebDataset)
- å¯ç”¨Flash Attention
- å¢åŠ  num_workers
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ

### é—®é¢˜3: Lossä¸ä¸‹é™

**æ£€æŸ¥æ¸…å•**:
- [ ] å­¦ä¹ ç‡æ˜¯å¦åˆé€‚ (1e-5åˆ°5e-5)
- [ ] æ•°æ®æ˜¯å¦æ­£ç¡®åŠ è½½
- [ ] æ ‡ç­¾æ˜¯å¦æ­£ç¡®å¯¹é½
- [ ] æ¢¯åº¦æ˜¯å¦æ­£å¸¸ (ä¸è¦æ¢¯åº¦çˆ†ç‚¸)

---

## ğŸ“ æ¯å‘¨æ£€æŸ¥æ¸…å•

### âœ… æ¯å‘¨å¿…åš
- [ ] æ£€æŸ¥è®­ç»ƒlossæ›²çº¿
- [ ] æŸ¥çœ‹æœ€æ–°æ£€æŸ¥ç‚¹æ€§èƒ½
- [ ] å¤‡ä»½é‡è¦æ¨¡å‹
- [ ] è®°å½•å®éªŒæ—¥å¿—
- [ ] æ›´æ–°æŠ€æœ¯æ–‡æ¡£

### âœ… æ¯æœˆå¿…åš
- [ ] å…¨é¢æ€§èƒ½è¯„ä¼°
- [ ] ä»£ç é‡æ„ä¼˜åŒ–
- [ ] æ•°æ®è´¨é‡åˆ†æ
- [ ] èµ„æºä½¿ç”¨ä¼˜åŒ–
- [ ] æŠ€æœ¯åˆ†äº«/æ±‡æŠ¥

---

## ğŸ¯ é˜¶æ®µæ€§ç›®æ ‡

### çŸ­æœŸç›®æ ‡ï¼ˆ1ä¸ªæœˆï¼‰
- âœ… å®Œæˆç¯å¢ƒæ­å»º
- âœ… éªŒè¯å®Œæ•´è®­ç»ƒæµç¨‹
- âœ… å®Œæˆå°è§„æ¨¡æ•°æ®é¢„è®­ç»ƒ
- âœ… åˆæ­¥è¯„ä¼°æ¨¡å‹èƒ½åŠ›

### ä¸­æœŸç›®æ ‡ï¼ˆ3ä¸ªæœˆï¼‰
- âœ… å®Œæˆå¤šæ¨¡æ€é¢„è®­ç»ƒ
- âœ… å®ŒæˆæŒ‡ä»¤å¾®è°ƒ
- âœ… è¾¾åˆ°åŸºå‡†æ€§èƒ½æŒ‡æ ‡
- âœ… ä¼˜åŒ–æ¨ç†é€Ÿåº¦

### é•¿æœŸç›®æ ‡ï¼ˆ6ä¸ªæœˆï¼‰
- âœ… è¾¾åˆ°æˆ–è¶…è¶ŠåŒç±»å¼€æºæ¨¡å‹
- âœ… å®Œæˆæ¨¡å‹éƒ¨ç½²
- âœ… æ’°å†™æŠ€æœ¯æŠ¥å‘Š
- âœ… å¼€æºæ¨¡å‹å’Œä»£ç 

---

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**: ä»ç¬¬1å‘¨Day1å¼€å§‹ï¼Œè¿è¡Œ `python scripts/verify_environment.py` âœ¨

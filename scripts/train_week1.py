"""
Week 1 è®­ç»ƒ - ä»…éªŒè¯è®­ç»ƒæµç¨‹ï¼ˆä¸åŠ è½½é¢„è®­ç»ƒLLMï¼‰
é€‚ç”¨äºå†…å­˜å—é™ç¯å¢ƒ
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent / 'src'))

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import yaml
import logging
from improved_vision_encoder import ImprovedVisionEncoder, ImprovedProjector
from production_trainer import ProductionTrainer
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MultimodalReasoningModel(nn.Module):
    """è½»é‡çº§å¤šæ¨¡æ€æ¨¡å‹ - ç”¨äºè®­ç»ƒ"""
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # è§†è§‰ç¼–ç å™¨
        self.vision_encoder = ImprovedVisionEncoder(
            img_size=384,
            patch_size=14,
            embed_dim=512,  # å‡å°åˆ°512
            depth=6,        # å‡å°åˆ°6å±‚
            num_heads=8,
            use_flash_attn=False  # CPUç¯å¢ƒå…³é—­
        )
        
        # æŠ•å½±å™¨
        self.vision_projection = ImprovedProjector(
            input_dim=512,
            output_dim=512,
            projector_type='token_pooling'
        )
        
        # ç®€å•çš„æ–‡æœ¬embeddingï¼ˆä¸ç”¨é¢„è®­ç»ƒï¼‰
        self.text_embedding = nn.Embedding(1000, 512)
        
        # å°å‹Transformerï¼ˆ3å±‚ï¼‰
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=512,
            nhead=8,
            dim_feedforward=2048,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=3)
        
        # è¾“å‡ºå¤´
        self.lm_head = nn.Linear(512, 1000)
        
        logger.info(f"è½»é‡çº§æ¨¡å‹åˆ›å»ºå®Œæˆ")
        total_params = sum(p.numel() for p in self.parameters()) / 1e6
        logger.info(f"æ€»å‚æ•°: {total_params:.1f}M")
    
    def forward(self, input_ids, images, attention_mask=None, labels=None):
        batch_size = input_ids.shape[0]
        
        # è§†è§‰ç‰¹å¾
        vision_features = self.vision_encoder(images)
        vision_embeds = self.vision_projection(vision_features)
        
        # æ–‡æœ¬embedding
        text_embeds = self.text_embedding(input_ids)
        
        # æ‹¼æ¥ [vision, text]
        combined = torch.cat([vision_embeds, text_embeds], dim=1)
        
        # Transformer
        hidden = self.transformer(combined)
        
        # é¢„æµ‹
        logits = self.lm_head(hidden)
        
        # è®¡ç®—loss
        loss = None
        if labels is not None:
            # åªå¯¹æ–‡æœ¬éƒ¨åˆ†è®¡ç®—loss
            text_logits = logits[:, vision_embeds.shape[1]:, :]
            loss = nn.functional.cross_entropy(
                text_logits.reshape(-1, 1000),
                labels.reshape(-1),
                ignore_index=-100
            )
        
        return {
            'loss': loss,
            'logits': logits,
            'hidden_states': hidden
        }


class SimpleDataset(Dataset):
    """è¶…ç®€å•æ•°æ®é›†"""
    
    def __init__(self, num_samples=100):
        self.num_samples = num_samples
    
    def __len__(self):
        return self.num_samples
    
    def __getitem__(self, idx):
        return {
            'input_ids': torch.randint(0, 1000, (64,)),
            'images': torch.randn(3, 384, 384),
            'labels': torch.randint(0, 1000, (64,))
        }


def collate_fn(batch):
    return {
        'input_ids': torch.stack([x['input_ids'] for x in batch]),
        'images': torch.stack([x['images'] for x in batch]),
        'labels': torch.stack([x['labels'] for x in batch])
    }


def main():
    logger.info("="*60)
    logger.info("Week 1 è®­ç»ƒ - ")
    logger.info("="*60)
    
    # åˆ›å»ºè½»é‡çº§æ¨¡å‹
    logger.info("\n[1/4] åˆ›å»ºè½»é‡çº§æ¨¡å‹...")
    model = MultimodalReasoningModel({})
    model = model.to("cuda")
    
    # åˆ›å»ºæ•°æ®é›†
    logger.info("\n[2/4] åˆ›å»ºæ•°æ®é›†...")
    dataset = SimpleDataset(num_samples=50)
    dataloader = DataLoader(
        dataset,
        batch_size=2,
        shuffle=True,
        num_workers=0,
        collate_fn=collate_fn
    )
    logger.info(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
    logger.info(f"æ‰¹æ¬¡æ•°: {len(dataloader)}")
    
    # è®­ç»ƒé…ç½®
    logger.info("\n[3/4] é…ç½®è®­ç»ƒå™¨...")
    config = {
        'learning_rate': 1e-4,
        'weight_decay': 0.01,
        'warmup_steps': 10,
        'total_steps': 100,
        'batch_size': 2,
        'gradient_accumulation': 4,
        'use_amp': False,  # CPUç¯å¢ƒå…³é—­
        'output_dir': 'outputs/week1',
        'save_steps': 25,
        'logging_steps': 5
    }
    
    trainer = ProductionTrainer(model, config)
    
    # è®­ç»ƒ
    logger.info("\n[4/4] å¼€å§‹è®­ç»ƒ...")
    logger.info(f"è®­ç»ƒ3ä¸ªepochï¼Œæ¯ä¸ªepoch {len(dataloader)} æ‰¹æ¬¡")
    
    try:
        for epoch in range(3):
            logger.info(f"\n{'='*60}")
            logger.info(f"Epoch {epoch + 1}/3")
            logger.info(f"{'='*60}")
            
            epoch_loss = trainer.train_epoch(dataloader, epoch + 1)
            
            logger.info(f"\nâœ… Epoch {epoch + 1} å®Œæˆ!")
            logger.info(f"  å¹³å‡Loss: {epoch_loss:.4f}")
            logger.info(f"  æœ€ä½³Loss: {trainer.best_loss:.4f}")
            logger.info(f"  å…¨å±€æ­¥æ•°: {trainer.global_step}")
        
        logger.info("\n" + "="*60)
        logger.info("ğŸ‰ è®­ç»ƒæˆåŠŸï¼")
        logger.info("="*60)
        logger.info(f"âœ… æ¨¡å‹ä¿å­˜: {trainer.output_dir / 'best_model.pt'}")
        logger.info(f"âœ… æ—¥å¿—æ–‡ä»¶: {trainer.output_dir / 'training_log.json'}")
        logger.info("\næ¥ä¸‹æ¥å¯ä»¥ï¼š")
        logger.info("  1. å¢åŠ Windowsè™šæ‹Ÿå†…å­˜ååŠ è½½çœŸå®LLM")
        logger.info("  2. è½¬åˆ°GPUç¯å¢ƒè¿›è¡Œå®Œæ•´è®­ç»ƒ")
        
    except Exception as e:
        logger.error(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

"""
æµ‹è¯•æ¨¡å‹æ¶æ„
éªŒè¯æ¨¡å‹å¯ä»¥æ­£å¸¸åˆ›å»ºå’Œå‰å‘ä¼ æ’­
"""
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import torch
from src.model_architecture import create_model

def test_model_creation():
    print("="*60)
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹æ¶æ„")
    print("="*60)
    
    print("\n1ï¸âƒ£ åˆ›å»ºæ¨¡å‹é…ç½®...")
    config = {
        'base_model': 'Qwen/Qwen2-7B',
        'vision_model': 'openai/clip-vit-large-patch14',
        'freeze_vision': True,
        'perceiver_depth': 2,
        'num_latents': 32,
        'enable_audio': False,
        'enable_cot': True,
        'enable_verification': True
    }
    
    print("é…ç½®:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    print("\n2ï¸âƒ£ åˆ›å»ºæ¨¡å‹...")
    try:
        model = create_model(config)
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\n3ï¸âƒ£ åˆ†ææ¨¡å‹å‚æ•°...")
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    frozen_params = total_params - trainable_params
    
    print(f"  æ€»å‚æ•°: {total_params/1e9:.2f}B ({total_params:,})")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params/1e9:.2f}B ({trainable_params:,})")
    print(f"  å†»ç»“å‚æ•°: {frozen_params/1e9:.2f}B ({frozen_params:,})")
    print(f"  å¯è®­ç»ƒæ¯”ä¾‹: {trainable_params/total_params*100:.2f}%")
    
    print("\n4ï¸âƒ£ æµ‹è¯•å‰å‘ä¼ æ’­...")
    batch_size = 2
    seq_len = 128
    
    try:
        input_ids = torch.randint(0, 1000, (batch_size, seq_len))
        attention_mask = torch.ones_like(input_ids)
        labels = input_ids.clone()
        
        print(f"  è¾“å…¥shape: {input_ids.shape}")
        
        with torch.no_grad():
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"  è¾“å‡ºlogits shape: {outputs['logits'].shape}")
        if outputs['loss'] is not None:
            print(f"  Loss: {outputs['loss'].item():.4f}")
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\n5ï¸âƒ£ æµ‹è¯•ç”ŸæˆåŠŸèƒ½...")
    try:
        with torch.no_grad():
            generated_ids = model.generate(
                input_ids=input_ids[:1],
                max_length=150,
                temperature=0.8
            )
        
        print(f"âœ… ç”Ÿæˆæµ‹è¯•æˆåŠŸ")
        print(f"  ç”Ÿæˆåºåˆ—é•¿åº¦: {generated_ids.shape[1]}")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\n6ï¸âƒ£ æ˜¾å­˜å ç”¨åˆ†æ...")
    if torch.cuda.is_available():
        print(f"  å·²åˆ†é…æ˜¾å­˜: {torch.cuda.memory_allocated()/1024**3:.2f} GB")
        print(f"  å·²ä¿ç•™æ˜¾å­˜: {torch.cuda.memory_reserved()/1024**3:.2f} GB")
    else:
        print("  (ä½¿ç”¨CPUï¼Œæ— GPUæ˜¾å­˜ç»Ÿè®¡)")
    
    print("\n" + "="*60)
    print("âœ… æ¨¡å‹æ¶æ„æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
    print("="*60)
    
    print("\nğŸ“ æ¨¡å‹æ¶æ„éªŒè¯æˆåŠŸï¼Œä¸‹ä¸€æ­¥:")
    print("  1. å‡†å¤‡è®­ç»ƒæ•°æ®")
    print("  2. é…ç½®è®­ç»ƒå‚æ•°: configs/training_config.yaml")
    print("  3. å¼€å§‹è®­ç»ƒ: python src/train_multimodal.py")
    
    return True

if __name__ == "__main__":
    success = test_model_creation()
    sys.exit(0 if success else 1)

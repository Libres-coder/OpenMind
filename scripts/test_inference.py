"""
OpenMind Agent æ¨ç†æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯è®­ç»ƒåçš„æ¨¡å‹å¯ä»¥æ­£å¸¸è¿›è¡Œæ¨ç†
"""

import os
import sys
import argparse
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.core import OpenMindAgent, AgentConfig


def load_model_from_checkpoint(checkpoint_path: str, device: str = "auto"):
    """ä»checkpointåŠ è½½æ¨¡å‹"""
    print(f"åŠ è½½checkpoint: {checkpoint_path}")
    
    # è®¾ç½®è®¾å¤‡
    if device == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(device)
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½checkpoint
    checkpoint = torch.load(checkpoint_path, map_location=device)
    print(f"Checkpoint keys: {list(checkpoint.keys())}")
    print(f"Global step: {checkpoint['global_step']}")
    print(f"Best eval loss: {checkpoint.get('best_eval_loss', 'N/A')}")
    
    # ä»checkpointè·å–é…ç½®
    config_dict = checkpoint.get('config', {})
    
    # åˆ›å»ºæ¨¡å‹é…ç½®
    agent_config = AgentConfig(
        hidden_size=config_dict.get('hidden_size', 768),
        max_cot_steps=config_dict.get('max_cot_steps', 5),
        img_size=config_dict.get('img_size', 224),
        patch_size=config_dict.get('patch_size', 16),
        vision_layers=config_dict.get('vision_layers', 6),
        fusion_layers=config_dict.get('fusion_layers', 4)
    )
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºOpenMindAgent...")
    model = OpenMindAgent(agent_config).to(device)
    
    # åŠ è½½æ¨¡å‹æƒé‡
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # åŠ è½½output_projï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    output_proj = None
    if 'output_proj_state_dict' in checkpoint:
        import torch.nn as nn
        output_proj = nn.Linear(config_dict.get('hidden_size', 768), 10).to(device)
        output_proj.load_state_dict(checkpoint['output_proj_state_dict'])
        output_proj.eval()
        print("âœ… output_projåŠ è½½æˆåŠŸ")
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    return model, output_proj, device, config_dict


def test_text_only_inference(model, output_proj, device, hidden_size):
    """æµ‹è¯•çº¯æ–‡æœ¬æ¨ç†"""
    print("\n" + "="*50)
    print("æµ‹è¯•1: çº¯æ–‡æœ¬æ¨ç†")
    print("="*50)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ–‡æœ¬åµŒå…¥
    batch_size = 2
    text_embedding = torch.randn(batch_size, hidden_size).to(device)
    
    with torch.no_grad():
        outputs = model(
            text_embedding=text_embedding,
            image=None,
            use_reasoning=True,
            use_evolution=True
        )
    
    print(f"è¾“å‡ºkeys: {list(outputs.keys())}")
    print(f"è¾“å‡ºshape: {outputs['output'].shape}")
    
    if output_proj is not None:
        logits = output_proj(outputs['output'])
        predictions = torch.argmax(logits, dim=-1)
        print(f"é¢„æµ‹ç±»åˆ«: {predictions.tolist()}")
    
    # æ£€æŸ¥å„æ¨¡å—è¾“å‡º
    if 'memory' in outputs:
        print(f"è®°å¿†æ¨¡å—: âœ… å·²å¯ç”¨")
    if 'reasoning' in outputs:
        print(f"æ¨ç†æ¨¡å—: âœ… å·²å¯ç”¨")
        if 'chain_of_thought' in outputs['reasoning']:
            cot = outputs['reasoning']['chain_of_thought']
            print(f"  - CoTæ­¥æ•°: {cot.get('num_steps', 'N/A')}")
    if 'evolution' in outputs:
        print(f"è¿›åŒ–æ¨¡å—: âœ… å·²å¯ç”¨")
        if 'evaluation' in outputs['evolution']:
            eval_score = outputs['evolution']['evaluation']['overall_score']
            print(f"  - è¯„ä¼°åˆ†æ•°: {eval_score.mean().item():.4f}")
    
    print("âœ… çº¯æ–‡æœ¬æ¨ç†æµ‹è¯•é€šè¿‡")
    return True


def test_multimodal_inference(model, output_proj, device, config_dict):
    """æµ‹è¯•å¤šæ¨¡æ€æ¨ç†"""
    print("\n" + "="*50)
    print("æµ‹è¯•2: å¤šæ¨¡æ€æ¨ç†ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰")
    print("="*50)
    
    hidden_size = config_dict.get('hidden_size', 768)
    img_size = config_dict.get('img_size', 224)
    
    # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
    batch_size = 2
    text_embedding = torch.randn(batch_size, hidden_size).to(device)
    image = torch.randn(batch_size, 3, img_size, img_size).to(device)
    
    with torch.no_grad():
        outputs = model(
            text_embedding=text_embedding,
            image=image,
            use_reasoning=True,
            use_evolution=True
        )
    
    print(f"è¾“å‡ºkeys: {list(outputs.keys())}")
    print(f"è¾“å‡ºshape: {outputs['output'].shape}")
    
    if output_proj is not None:
        logits = output_proj(outputs['output'])
        predictions = torch.argmax(logits, dim=-1)
        print(f"é¢„æµ‹ç±»åˆ«: {predictions.tolist()}")
    
    # æ£€æŸ¥è§†è§‰æ¨¡å—
    if 'vision' in outputs:
        print(f"è§†è§‰æ¨¡å—: âœ… å·²å¯ç”¨")
        vision_out = outputs['vision']
        if 'visual_features' in vision_out:
            print(f"  - è§†è§‰ç‰¹å¾shape: {vision_out['visual_features'].shape}")
    
    print("âœ… å¤šæ¨¡æ€æ¨ç†æµ‹è¯•é€šè¿‡")
    return True


def test_reasoning_steps(model, device, hidden_size):
    """æµ‹è¯•æ¨ç†æ­¥éª¤"""
    print("\n" + "="*50)
    print("æµ‹è¯•3: æ¨ç†é“¾è¯¦æƒ…")
    print("="*50)
    
    text_embedding = torch.randn(1, hidden_size).to(device)
    
    with torch.no_grad():
        outputs = model(
            text_embedding=text_embedding,
            image=None,
            use_reasoning=True,
            use_evolution=False
        )
    
    if 'reasoning' in outputs:
        reasoning = outputs['reasoning']
        print(f"æ¨ç†æ¨¡å—è¾“å‡ºkeys: {list(reasoning.keys())}")
        
        if 'chain_of_thought' in reasoning:
            cot = reasoning['chain_of_thought']
            print(f"CoT keys: {list(cot.keys())}")
            if 'final_state' in cot:
                print(f"æœ€ç»ˆçŠ¶æ€shape: {cot['final_state'].shape}")
        
        if 'verification' in reasoning:
            print(f"éªŒè¯ç»“æœ: {reasoning['verification']}")
    
    print("âœ… æ¨ç†é“¾æµ‹è¯•é€šè¿‡")
    return True


def test_memory_system(model, device, hidden_size):
    """æµ‹è¯•è®°å¿†ç³»ç»Ÿ"""
    print("\n" + "="*50)
    print("æµ‹è¯•4: è®°å¿†ç³»ç»Ÿ")
    print("="*50)
    
    text_embedding = torch.randn(1, hidden_size).to(device)
    
    # ç¬¬ä¸€æ¬¡æ¨ç†
    with torch.no_grad():
        outputs1 = model(
            text_embedding=text_embedding,
            image=None,
            use_reasoning=False,
            use_evolution=False
        )
    
    if 'memory' in outputs1:
        memory = outputs1['memory']
        print(f"è®°å¿†æ¨¡å—è¾“å‡ºkeys: {list(memory.keys())}")
        
        if 'short_term' in memory:
            print(f"çŸ­æœŸè®°å¿†: âœ…")
        if 'long_term' in memory:
            print(f"é•¿æœŸè®°å¿†: âœ…")
    
    print("âœ… è®°å¿†ç³»ç»Ÿæµ‹è¯•é€šè¿‡")
    return True


def run_all_tests(checkpoint_path: str, device: str = "auto"):
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("="*60)
    print("OpenMind Agent æ¨ç†æµ‹è¯•")
    print("="*60)
    
    # åŠ è½½æ¨¡å‹
    model, output_proj, device, config_dict = load_model_from_checkpoint(
        checkpoint_path, device
    )
    
    hidden_size = config_dict.get('hidden_size', 768)
    
    # è¿è¡Œæµ‹è¯•
    results = {}
    
    try:
        results['text_only'] = test_text_only_inference(
            model, output_proj, device, hidden_size
        )
    except Exception as e:
        print(f"âŒ çº¯æ–‡æœ¬æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        results['text_only'] = False
    
    try:
        results['multimodal'] = test_multimodal_inference(
            model, output_proj, device, config_dict
        )
    except Exception as e:
        print(f"âŒ å¤šæ¨¡æ€æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        results['multimodal'] = False
    
    try:
        results['reasoning'] = test_reasoning_steps(model, device, hidden_size)
    except Exception as e:
        print(f"âŒ æ¨ç†é“¾æµ‹è¯•å¤±è´¥: {e}")
        results['reasoning'] = False
    
    try:
        results['memory'] = test_memory_system(model, device, hidden_size)
    except Exception as e:
        print(f"âŒ è®°å¿†ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        results['memory'] = False
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*60)
    
    all_passed = True
    for test_name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if not passed:
            all_passed = False
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å‹å¯ä»¥æ­£å¸¸è¿›è¡Œæ¨ç†ã€‚")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹ã€‚")
    
    return all_passed


def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•OpenMind Agentæ¨ç†")
    parser.add_argument("--checkpoint", type=str, required=True,
                       help="Checkpointæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--device", type=str, default="auto",
                       help="è®¾å¤‡ (auto/cuda/cpu)")
    args = parser.parse_args()
    
    if not os.path.exists(args.checkpoint):
        print(f"âŒ Checkpointä¸å­˜åœ¨: {args.checkpoint}")
        sys.exit(1)
    
    success = run_all_tests(args.checkpoint, args.device)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
